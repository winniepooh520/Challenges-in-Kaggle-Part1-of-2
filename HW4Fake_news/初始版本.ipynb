{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HW4 - Fake News Detection\n",
    "本次作業將針對假新聞作分析，預測一則新聞是否reliable (繳交期限：12/10 23:55)\n",
    "1: fake\n",
    "0: true\n",
    "請分別利用GBDT、LightGBM、xgboost對\"train.csv\"的資料建模，並用\"test.csv\"進行測試\n",
    "註：\"test.csv\"的label在\"sample_submission.csv\"裡面\n",
    "(資料來源：https://www.kaggle.com/c/fakenewskdd2020/data)\n",
    "\n",
    "作業流程：\n",
    "\n",
    "1. 資料前處理\n",
    " a. 讀取\"train.csv\"與\"test.csv\"並利用分割符號切割、建立train&test之DataFrame\n",
    "註：分割符號為tab(\\t)\n",
    "\n",
    " b. 去除停頓詞stop words \n",
    "可參考：\n",
    "sklearn.feature_extraction.text.CountVectorizer\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "自訂stop words\n",
    "https://stackoverflow.com/questions/52712254/how-to-eliminate-stop-words-only-using-scikit-learn\n",
    "\n",
    " c. 文字探勘前處理，將文字轉換成向量，像是常見的方法 tf-idf、word2vec...等\n",
    "\n",
    "可參考：\n",
    "sklearn.feature_extraction.text.TfidfVectorizer\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "\n",
    "Word2vec\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "2. 建模：分別使用以下三種模型\n",
    "xgboost\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_intro.html#install-xgboost\n",
    "\n",
    "GBDT\n",
    "\n",
    "LightGBM\n",
    "https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/\n",
    "\n",
    "3. 評估模型\n",
    "利用\"test.csv\"的資料對2.所建立的模型進行測試，並計算Accuracy、Precision、Recall、F-measure\n",
    "\n",
    "請將以下檔案壓縮成 HW4_學號_姓名.zip：\n",
    "\n",
    "1. 討論報告PDF (含截圖跟簡短說明、討論等等)，需提及：\n",
    "文字探勘前處理的方法\n",
    "GBDT、LightGBM、xgboost 模型之結果比較\n",
    "\n",
    "2. Python程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get the latest from TODAY Sign up for our news...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d  Conan On The Funeral Trump Will Be Invited...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It’s safe to say that Instagram Stories has fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Much like a certain Amazon goddess with a lass...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At a time when the perfect outfit is just one ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Get the latest from TODAY Sign up for our news...     1\n",
       "1  2d  Conan On The Funeral Trump Will Be Invited...     1\n",
       "2  It’s safe to say that Instagram Stories has fa...     0\n",
       "3  Much like a certain Amazon goddess with a lass...     0\n",
       "4  At a time when the perfect outfit is just one ...     0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", sep='\\t', encoding='utf-8')\n",
    "test = pd.read_csv(\"test.csv\", sep='\\t', encoding='utf-8')\n",
    "test_label = pd.read_csv(\"sample_submission.csv\", sep='\\t', encoding='utf-8')\n",
    "train.head()\n",
    "\n",
    "# type(train) : pandas.core.frame.DataFrame\n",
    "# train.columns : Index(['text', 'label'], dtype='object')\n",
    "# print( len(train['text'])): 4987\n",
    "# print(len(test['text'])): 1247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1247 entries, 0 to 1246\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id,label  1247 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 9.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>The 2017 Teen Choice Awards ceremony was held ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>The concert, part of “The Joshua Tree Tour,” w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Selena Gomez refuses to talk to her mother abo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>This is worse than a lump of coal in your stoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Luann De Lesseps is going to rehab after her a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>1244</td>\n",
       "      <td>Get the latest from TODAY Sign up for our news...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>1245</td>\n",
       "      <td>Jaden Smith claims that the Four Seasons Hotel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>1246</td>\n",
       "      <td>Overview (3)  Mini Bio (1)  Faith Hill was bor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1247</td>\n",
       "      <td>CLOSE Aaron Paul dishes on 'The Path'  Aaron P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1248</td>\n",
       "      <td>Meghan Edmonds was showered with love at her b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1247 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  label\n",
       "0        2  The 2017 Teen Choice Awards ceremony was held ...      1\n",
       "1        3  The concert, part of “The Joshua Tree Tour,” w...      1\n",
       "2        4  Selena Gomez refuses to talk to her mother abo...      0\n",
       "3        5  This is worse than a lump of coal in your stoc...      0\n",
       "4        6  Luann De Lesseps is going to rehab after her a...      0\n",
       "...    ...                                                ...    ...\n",
       "1242  1244  Get the latest from TODAY Sign up for our news...      0\n",
       "1243  1245  Jaden Smith claims that the Four Seasons Hotel...      0\n",
       "1244  1246  Overview (3)  Mini Bio (1)  Faith Hill was bor...      1\n",
       "1245  1247  CLOSE Aaron Paul dishes on 'The Path'  Aaron P...      1\n",
       "1246  1248  Meghan Edmonds was showered with love at her b...      1\n",
       "\n",
       "[1247 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把 sample_submission.csv 中的 id 與 label切開，再塞入 test\n",
    "\n",
    "label=[]\n",
    "for i in range(len(test_label[\"id,label\"])):\n",
    "    temp_label = test_label[\"id,label\"][i][-1]\n",
    "    label.append(int(temp_label))\n",
    "    \n",
    "test_label[\"label\"]=label\n",
    "\n",
    "test[\"label\"]= test_label[\"label\"]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get the latest from TODAY Sign up for our newsletter  No one ever truly gets over losing a loved one, and Blake Shelton is no exception. He was just 14 when his older brother Richie died on Nov. 13, 1990. And, as Shelton noted in a tweet Monday, \"It changed my life forever.\"  Richie was 24 when he died in a car accident in the Sheltons\\' home state of Oklahoma. Two years ago, Shelton sent out a message for the 25th anniversary of his loss:  Richie, who was Blake\\'s half-brother (they shared a mother), was a passenger in a car that collided with a school bus in Ada, south of Oklahoma City.  Richie, driver Redena McManus and a 3-year-old boy, Christopher McManus, all died during or shortly after the collision, while the bus driver and passengers were uninjured, according to police reports.  The accident has clearly remained with Blake, who told 60 Minutes in 2014, \"I remember picking up the phone to call him a week after he was dead, to tell him something. I was picking up the phone to call him, to tell him something I just saw on TV or, and it was like constantly a shock to me that he was dead.\"  Blake Shelton playing at TODAY\\'s Halloween Extravaganza in New York City on Oct. 31. Getty Images  In 2011, Blake and his then-wife Miranda Lambert wrote a single called \"Over You,\" which was inspired by Richie.  Still, the two brothers had bonded despite the age difference; both shared a love of country music. \"His bedroom was right across the hallway from mine when I was little,\" Blake said in that interview. \"And he was listening to Hank Williams, Jr. or Waylon, Lynyrd Skynyrd or Bob Seeger. I just, whatever was popular really, Richie loved all music.  \"And I would be sitting there going, \\'Man, that guy\\'s my hero. That\\'s the coolest guy. He’s my big brother.\\'\"  Follow Randee Dawn on Twitter.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4987 entries, 0 to 4986\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    4987 non-null   object\n",
      " 1   label   4987 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1247 entries, 0 to 1246\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      1247 non-null   int64 \n",
      " 1   text    1247 non-null   object\n",
      " 2   label   1247 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 29.4+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[\"label\"].value_counts()\n",
    "# 0        2972\n",
    "# 1        2014\n",
    "# label       1\n",
    "# Name: label, dtype: int64\n",
    "# 有個 label夾在0.1裡面，抓出來刪掉row\n",
    "\n",
    "# a=0\n",
    "# for i in train[\"label\"]:\n",
    "#     if i!=\"label\":\n",
    "#         a+=1\n",
    "#     if i==\"label\":\n",
    "#         break\n",
    "# a=1615\n",
    "train = train.drop([1615])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2972\n",
       "1    2014\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 引用 NLTK 的 stop words list\n",
    "stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# 將文字轉成向量，同時 去除停頓詞stop words \n",
    "vectorizer = CountVectorizer(stop_words=stop_words, max_features=2500)\n",
    "\n",
    "train_vector = vectorizer.fit_transform(train[\"text\"]).toarray()\n",
    "test_vector = vectorizer.fit_transform(test[\"text\"]).toarray()\n",
    "\n",
    "# print(vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transform = TfidfTransformer()    # 使用TF-IDF（詞頻、逆文檔頻率）應用於稀疏矩陣\n",
    "Y = transform.fit_transform(X)    # 使用上面CountVectorizer處理後的 X 數據\n",
    "print(Y.toarray())                # 輸出轉換爲tf-idf後的 Y 矩陣，同樣直接打印 Y 輸出每個數據的位置\n",
    "print(vectorizer.get_feature_names())    # 打印特徵名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "for i in train_vector[0]:\n",
    "    if i > 1:\n",
    "        print(i)\n",
    "        a+=1\n",
    "        if a>5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_vector\n",
    "train_y = train[\"label\"].values\n",
    "test_X = test_vector\n",
    "test_y = test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "xgboost\n",
    "\"\"\"\n",
    "import xgboost as xgb\n",
    "\n",
    "# read in data\n",
    "dtrain = xgb.DMatrix(train_X , label=train_y)\n",
    "dtest = xgb.DMatrix(test_X , label=test_y)\n",
    "# specify parameters via map\n",
    "param = {'max_depth': 25, 'eta': 1, 'objective': 'reg:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "\n",
    "num_round = 5 # 2:電腦跑10秒、5:電腦跑30秒外加風扇全開，決定跑到5就好，不要虐待電腦。recall從0.1升到0.2已經夠了。\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "#After training, the model can be saved.\n",
    "bst.save_model('0001.model')\n",
    "\n",
    "#A saved model can be loaded as follows:\n",
    "bst = xgb.Booster({'nthread': 4})  # init model\n",
    "bst.load_model('0001.model')  # load data\n",
    "\n",
    "# make prediction\n",
    "#preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測數據集 \n",
    "y_pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#畫出 XGB的樹\n",
    "xgb.to_graphviz(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost precision= 0.47985347985347987\n",
      "XGboost recall= 0.21231766612641814\n",
      "XGboost accuracy= 0.4963913392141139\n",
      "XGboost f1_score= 0.2943820224719101\n"
     ]
    }
   ],
   "source": [
    "# 計算Precision, Recall, Accuracy\n",
    "# II. 函式計算\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "precision = precision_score(test_y,y_pred.round())\n",
    "recall = recall_score(test_y,y_pred.round())\n",
    "accuracy = accuracy_score(test_y,y_pred.round())\n",
    "f1_measure = f1_score(test_y,y_pred.round())\n",
    "print(\"XGboost precision=\",precision)\n",
    "print(\"XGboost recall=\",recall)\n",
    "print(\"XGboost accuracy=\",accuracy)\n",
    "print(\"XGboost f1_score=\",f1_measure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=[]\n",
    "for i in train[\"label\"]:\n",
    "    a = int(i)\n",
    "    train_y.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_vector\n",
    "train_y = train_y\n",
    "test_X = test_vector\n",
    "test_y = test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "GBDT\n",
    "\"\"\"\n",
    "# from sklearn.experimental import enable_hist_gradient_boosting\n",
    "# from sklearn import ensemble\n",
    "\n",
    "# model = ensemble.HistGradientBoostingClassifier()\n",
    "# model.fit(train_X, train_y)\n",
    "# y_pred_GBDT=model.predict(test_X)\n",
    "# 跑超過4分鐘，終於沒有error，但是整個chrome跳出\"記憶體滿載\"的提示後強制關閉\n",
    "\n",
    "# 跑超過1小時，只好先中止\n",
    "# from GBDT.gbdt import GradientBoostingBinaryClassifier\n",
    "# model = GradientBoostingBinaryClassifier(learning_rate=0.1, max_depth=10)\n",
    "# model.fit(train_X, train_y)\n",
    "# y_pred_GBDT=model.predict(test_X)\n",
    "\n",
    "# 為什麼跑5分鐘都跑不出來東西RRR，又不是多大的模型\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GBDT = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT precision= 0.5158924205378973\n",
      "GBDT recall= 0.3419773095623987\n",
      "GBDT accuracy= 0.5156375300721732\n",
      "GBDT f1_score= 0.41130604288499023\n"
     ]
    }
   ],
   "source": [
    "# 計算Precision, Recall, Accuracy\n",
    "# II. 函式計算\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "precision = precision_score(test_y,y_pred_GBDT.round())\n",
    "recall = recall_score(test_y,y_pred_GBDT.round())\n",
    "accuracy = accuracy_score(test_y,y_pred_GBDT.round())\n",
    "f1_measure = f1_score(test_y,y_pred_GBDT.round())\n",
    "print(\"GBDT precision=\",precision)\n",
    "print(\"GBDT recall=\",recall)\n",
    "print(\"GBDT accuracy=\",accuracy)\n",
    "print(\"GBDT f1_score=\",f1_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT precision= 0.5158924205378973\n",
      "GBDT recall= 0.3419773095623987\n",
      "GBDT accuracy= 0.5156375300721732\n",
      "GBDT f1_score= 0.41130604288499023\n"
     ]
    }
   ],
   "source": [
    "# 計算Precision, Recall, Accuracy\n",
    "# II. 函式計算\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "precision = precision_score(test_y,y_pred_GBDT)\n",
    "recall = recall_score(test_y,y_pred_GBDT)\n",
    "accuracy = accuracy_score(test_y,y_pred_GBDT)\n",
    "f1_measure = f1_score(test_y,y_pred_GBDT)\n",
    "print(\"GBDT precision=\",precision)\n",
    "print(\"GBDT recall=\",recall)\n",
    "print(\"GBDT accuracy=\",accuracy)\n",
    "print(\"GBDT f1_score=\",f1_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0)\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.predict(X_test[:2])\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65240858,  0.49374178,  1.30184623, ..., -1.30819171,\n",
       "        -1.04525337, -0.11054066],\n",
       "       [ 0.35178011, -0.47003288, -0.37914756, ..., -2.38076394,\n",
       "        -0.11048941, -1.55042935],\n",
       "       [-1.58249448, -1.42279491, -0.56430103, ...,  1.26661394,\n",
       "        -1.31771734,  1.61805427],\n",
       "       ...,\n",
       "       [-0.96050438, -2.28862004,  1.02943883, ..., -0.79347019,\n",
       "         1.12859406, -0.27567053],\n",
       "       [ 0.91017891,  0.78632796,  0.06326199, ...,  0.42234144,\n",
       "        -0.46359597, -0.01702041],\n",
       "       [-0.87916063, -1.63880731, -0.30769128, ..., -0.6054158 ,\n",
       "         1.57886519,  0.73165893]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2014, number of negative: 2972\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 42462\n",
      "[LightGBM] [Info] Number of data points in the train set: 4986, number of used features: 7978\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.403931 -> initscore=-0.389112\n",
      "[LightGBM] [Info] Start training from score -0.389112\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Light GBM\n",
    "\"\"\"\n",
    "\n",
    "import lightgbm as lgb \n",
    "\n",
    "train_data = lgb.Dataset(train_X , label=train_y)\n",
    "\n",
    "param = {'num_leaves': 31, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "\n",
    "num_round = 10\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "\n",
    "# After training, the model can be saved:\n",
    "bst.save_model('model.txt')\n",
    "\n",
    "# A saved model can be loaded:\n",
    "bst = lgb.Booster(model_file='model.txt')  # init model\n",
    "\n",
    "ypred_LightGBM = bst.predict(test_X, predict_disable_shape_check=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM precision= 0.49390243902439024\n",
      "Light GBM recall= 0.1312803889789303\n",
      "Light GBM accuracy= 0.5036086607858862\n",
      "Light GBM f1_score= 0.20742637644046094\n"
     ]
    }
   ],
   "source": [
    "# 計算Precision, Recall, Accuracy\n",
    "# II. 函式計算\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "precision_LightGBM = precision_score(test_y,ypred_LightGBM.round())\n",
    "recall_LightGBM = recall_score(test_y,ypred_LightGBM.round())\n",
    "accuracy_LightGBM = accuracy_score(test_y,ypred_LightGBM.round())\n",
    "f1_measure_LightGBM = f1_score(test_y,ypred_LightGBM.round())\n",
    "print(\"Light GBM precision=\",precision_LightGBM)\n",
    "print(\"Light GBM recall=\",recall_LightGBM)\n",
    "print(\"Light GBM accuracy=\",accuracy_LightGBM)\n",
    "print(\"Light GBM f1_score=\",f1_measure_LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
